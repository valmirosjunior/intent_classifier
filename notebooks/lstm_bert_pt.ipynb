{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zL6SjRcWyrkQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 17:38:48.209844: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-19 17:38:48.209862: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Bidirectional, Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from src.core import file_manager as fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrUF3yEQzc7z",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fm.read_annotated_df_with_embeddings('bert_pt')\n",
    "\n",
    "count_before = df.txt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was deleted 21 rows with bad representation\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[df.apply(lambda x: (len(x['tokens']) == len(x['word_embeddings'])) , axis=1)]\n",
    "\n",
    "rows_delted = count_before - df.txt.count()\n",
    "\n",
    "print(f'There was deleted {rows_delted} rows with bad representation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6231\n"
     ]
    }
   ],
   "source": [
    "vocab = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "  for index, token in enumerate(row['tokens']):\n",
    "    if token not in vocab:\n",
    "      vocab[token] = row['word_embeddings'][index]\n",
    "\n",
    "n_source_words = len(vocab)\n",
    "\n",
    "print(n_source_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inform_symptoms    5474\n",
       "request_inform     1278\n",
       "greeting           1175\n",
       "inform_medicine     889\n",
       "Name: intent, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['intent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xptKqUwex1j2",
    "outputId": "0d63258f-2de3-4411-db43-503f87d5986e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n"
     ]
    }
   ],
   "source": [
    "max_len = df['tokens'].apply(lambda x : len(x)).max()\n",
    "print(max_len)\n",
    "# max_len = 700 #75% do dataset pelo menos tem no maximo esse valor de tamanho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0GiyMsQejy3G",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_embedding_matrix(vocab, n_words, emb_size):\n",
    "    \n",
    "    pret_embedding = {}\n",
    "    embedding_matrix = np.zeros((n_words, emb_size))\n",
    "    count = 0\n",
    "\n",
    "    # Dicionário com todos os ids e palavras do embedding pré-treinado\n",
    "    # for index, word in enumerate(vocab.index_to_key):\n",
    "    for index, word in enumerate(vocab.keys()):\n",
    "      pret_embedding[word] = index\n",
    "\n",
    "    # Construindo a embedding_matrix do embedding pré-treinado\n",
    "    for item in pret_embedding.items():\n",
    "      if item[1] < n_words:\n",
    "        count += 1\n",
    "        embedding_vector = vocab[item[0]]\n",
    "        if embedding_vector is not None:\n",
    "          embedding_matrix[item[1]] = embedding_vector\n",
    "      \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GmIJNhfYDH8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Save the vectors  in a new Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "1lPLrypQaxMd",
    "outputId": "f85dd86b-ff35-44bb-8c49-582c6bbe0f50",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6231, 768)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding_size = 300\n",
    "embedding_size = len(df.loc[0].word_embeddings[0])\n",
    "embedding_matrix = create_embedding_matrix(vocab, n_source_words, embedding_size)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_key_2_index =  {key: index for index, key in enumerate(vocab.keys())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umj8ZOBwbT4C",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que cria o X\n",
    "def create_x(tokens):\n",
    "    list_x = []\n",
    "    for token in tokens:\n",
    "      if(token in vocab_key_2_index):\n",
    "        list_x.append(vocab_key_2_index[token])\n",
    "      \n",
    "    return list_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>annotated_txt</th>\n",
       "      <th>intent</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_embeddings</th>\n",
       "      <th>token_indexes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tô  muito nervosa Marcela com tudo isso</td>\n",
       "      <td>Tô  muito nervosa Marcela com tudo isso</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>[[-0.17518604000000002, -0.38116214, 0.1568575...</td>\n",
       "      <td>[Tô, muito, nervosa, Marcela, com, tudo, isso]</td>\n",
       "      <td>[[0.10563439000000001, -0.6496529600000001, 0....</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Com muito medo</td>\n",
       "      <td>Com muito medo</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>[[0.40117407, -0.22014676, 0.1467775, 0.185312...</td>\n",
       "      <td>[Com, muito, medo]</td>\n",
       "      <td>[[0.5744509, -0.58911455, 0.11015732600000001,...</td>\n",
       "      <td>[7, 1, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Não</td>\n",
       "      <td>Não</td>\n",
       "      <td>greeting</td>\n",
       "      <td>[[0.0857483, -0.41115219999999997, 0.28060192,...</td>\n",
       "      <td>[Não]</td>\n",
       "      <td>[[0.0857483, -0.41115219999999997, 0.28060192,...</td>\n",
       "      <td>[9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tem algum remédio  que a pessoa tome para se a...</td>\n",
       "      <td>Tem algum remédio  que a pessoa tome para se a...</td>\n",
       "      <td>request_inform</td>\n",
       "      <td>[[-0.018409189, -0.17020282, 0.273364780000000...</td>\n",
       "      <td>[Tem, algum, remédio, que, a, pessoa, tome, pa...</td>\n",
       "      <td>[[-0.026540479000000002, -0.44967073, 0.199957...</td>\n",
       "      <td>[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tá  certo</td>\n",
       "      <td>Tá  certo</td>\n",
       "      <td>greeting</td>\n",
       "      <td>[[0.2476745, -0.31360537, 0.040109605, 0.37392...</td>\n",
       "      <td>[Tá, certo]</td>\n",
       "      <td>[[0.29746079999999997, -0.3857502, 0.25457925,...</td>\n",
       "      <td>[20, 21]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 txt  \\\n",
       "0            Tô  muito nervosa Marcela com tudo isso   \n",
       "1                                     Com muito medo   \n",
       "2                                                Não   \n",
       "3  Tem algum remédio  que a pessoa tome para se a...   \n",
       "4                                          Tá  certo   \n",
       "\n",
       "                                       annotated_txt           intent  \\\n",
       "0            Tô  muito nervosa Marcela com tudo isso  inform_symptoms   \n",
       "1                                     Com muito medo  inform_symptoms   \n",
       "2                                                Não         greeting   \n",
       "3  Tem algum remédio  que a pessoa tome para se a...   request_inform   \n",
       "4                                          Tá  certo         greeting   \n",
       "\n",
       "                                          embeddings  \\\n",
       "0  [[-0.17518604000000002, -0.38116214, 0.1568575...   \n",
       "1  [[0.40117407, -0.22014676, 0.1467775, 0.185312...   \n",
       "2  [[0.0857483, -0.41115219999999997, 0.28060192,...   \n",
       "3  [[-0.018409189, -0.17020282, 0.273364780000000...   \n",
       "4  [[0.2476745, -0.31360537, 0.040109605, 0.37392...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0     [Tô, muito, nervosa, Marcela, com, tudo, isso]   \n",
       "1                                 [Com, muito, medo]   \n",
       "2                                              [Não]   \n",
       "3  [Tem, algum, remédio, que, a, pessoa, tome, pa...   \n",
       "4                                        [Tá, certo]   \n",
       "\n",
       "                                     word_embeddings  \\\n",
       "0  [[0.10563439000000001, -0.6496529600000001, 0....   \n",
       "1  [[0.5744509, -0.58911455, 0.11015732600000001,...   \n",
       "2  [[0.0857483, -0.41115219999999997, 0.28060192,...   \n",
       "3  [[-0.026540479000000002, -0.44967073, 0.199957...   \n",
       "4  [[0.29746079999999997, -0.3857502, 0.25457925,...   \n",
       "\n",
       "                              token_indexes  \n",
       "0                     [0, 1, 2, 3, 4, 5, 6]  \n",
       "1                                 [7, 1, 8]  \n",
       "2                                       [9]  \n",
       "3  [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]  \n",
       "4                                  [20, 21]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['token_indexes'] = df['tokens'].apply(lambda tokens : create_x(tokens))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8816, 103), (8816, 4))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pad_sequences(maxlen=max_len, sequences=df['token_indexes'], value=0, padding='post', truncating='post')\n",
    "Y = pd.get_dummies(df['intent']).values\n",
    "(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NDzsrjXk4sU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "pbaMEtTVk67l",
    "outputId": "8d3fe25a-2041-4ac9-a788-2cf07a156f8a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7052, 103) (7052, 4)\n",
      "(1764, 103) (1764, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42,stratify=Y)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjRDbCNoPaoz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "M_iUMZidPGBV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 17:39:11.658851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-19 17:39:11.659963: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-19 17:39:11.660013: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-19 17:39:11.660068: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-19 17:39:11.660100: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-06-19 17:39:11.660129: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-06-19 17:39:11.660176: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-19 17:39:11.660211: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-06-19 17:39:11.660241: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-06-19 17:39:11.660246: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-06-19 17:39:11.660837: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "num_labels = Y.shape[1]\n",
    "MAX_NB_WORDS = n_source_words\n",
    "# EMBEDDING_DIM = 50\n",
    "EMBEDDING_DIM = embedding_size\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1], weights=[embedding_matrix]))\n",
    "# model.add(Embedding(X.shape[0], X.shape[1], input_length=X.shape[1], weights=[X]))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#Optimisation functions usually calculate the gradient i.e. the partial derivative of loss function with respect to weights, \n",
    "#and the weights are modified in the opposite direction of the calculated gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "iaMmhU8a47I6",
    "outputId": "bfc5473a-d5ab-4080-aad2-e56e49b7712e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 103, 768)          4785408   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              426496    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,212,420\n",
      "Trainable params: 5,212,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4l4iZ8z9gFgF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_model = fm.filename_from_data_dir(f'output/patient/lstm_models/bert_pt.h5')\n",
    "#model.load_weights(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "aWhGma7KPe5Q",
    "outputId": "59c72d10-a8e1-444c-e125-2f8dacfbb791",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 15s 129ms/step - loss: 0.4816 - accuracy: 0.8232 - val_loss: 0.3260 - val_accuracy: 0.8669\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.1932 - accuracy: 0.9237 - val_loss: 0.2125 - val_accuracy: 0.9150\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 0.1190 - accuracy: 0.9578 - val_loss: 0.2181 - val_accuracy: 0.9136\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.0708 - accuracy: 0.9783 - val_loss: 0.2313 - val_accuracy: 0.9278\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 0.0423 - accuracy: 0.9880 - val_loss: 0.2572 - val_accuracy: 0.9122\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1, \n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = fm.filename_from_data_dir(f'output/lstm_models/patient/bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "uRrwj82JYEP6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the model\n"
     ]
    }
   ],
   "source": [
    "print('saving the model')\n",
    "model.save(f'{working_dir}/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the vocabullary\n"
     ]
    }
   ],
   "source": [
    "print('saving the vocabullary')\n",
    "\n",
    "file = open(f'{working_dir}/vocabullary.json',\"w\")\n",
    "\n",
    "file.write(json.dumps(vocab_key_2_index))\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the metadata\n"
     ]
    }
   ],
   "source": [
    "print('saving the metadata')\n",
    "\n",
    "file = open(f'{working_dir}/metadata.json',\"w\")\n",
    "\n",
    "intents = pd.get_dummies(df['intent']).columns.tolist()\n",
    "\n",
    "metadata = {\n",
    "  'intents': intents,\n",
    "  'vector_length': str(max_len)\n",
    "}\n",
    "\n",
    "file.write(json.dumps(metadata))\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OtcdG7lQKWe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "UAW8hzQWQA_6",
    "outputId": "df64dc70-e57d-464e-877a-8c6c78f75bf8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 1s 17ms/step - loss: 0.2274 - accuracy: 0.9257\n",
      "Test set\n",
      "  Loss: 0.227\n",
      "  Accuracy: 0.926\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[Pará State]Text_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
