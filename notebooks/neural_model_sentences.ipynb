{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zL6SjRcWyrkQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 21:17:09.410625: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-07 21:17:09.410638: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import os\n",
    "import random as rn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from src.core import file_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_seed(verbosity=True):\n",
    "  if verbosity:\n",
    "    print('Applying seed')\n",
    "  SEED = 42\n",
    "  os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "  np.random.seed(SEED)\n",
    "  rn.seed(SEED)\n",
    "  tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(embedding_dim, num_labels):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(64, activation='softmax', input_shape=(embedding_dim,)))\n",
    "  model.add(Dropout(0.1))\n",
    "  model.add(Dense(num_labels, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(embedding_name):\n",
    "  apply_seed()\n",
    "  print('loading df')\n",
    "  \n",
    "  df = fm.read_annotated_df_with_embeddings(embedding_name)\n",
    "\n",
    "  X = np.array(df['embeddings'].map(lambda x: np.array(x[0])).to_list())\n",
    "  Y = pd.get_dummies(df['intent']).values\n",
    "\n",
    "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "  model = build_model(X.shape[1], Y.shape[1])\n",
    "\n",
    "  print('training model')\n",
    "  history = model.fit(X_train, Y_train, epochs=20, batch_size=64,validation_split=0.1, verbose=0,\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "\n",
    "  accr = model.evaluate(X_test,Y_test)\n",
    "  print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
    "  \n",
    "  path_model = fm.filename_from_data_dir(f'output/neural_models/patient/{embedding_name}/model.h5')\n",
    "  # print(f'Saving the model at: {path_model}')\n",
    "  model.save(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "loading df\n",
      "training model\n",
      "83/83 [==============================] - 0s 553us/step - loss: 0.2889 - accuracy: 0.9163\n",
      "Test set\n",
      "  Loss: 0.289\n",
      "  Accuracy: 0.916\n"
     ]
    }
   ],
   "source": [
    "run_pipeline('bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "loading df\n",
      "training model\n",
      "83/83 [==============================] - 0s 726us/step - loss: 0.2584 - accuracy: 0.9268\n",
      "Test set\n",
      "  Loss: 0.258\n",
      "  Accuracy: 0.927\n"
     ]
    }
   ],
   "source": [
    "run_pipeline('flair_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "loading df\n",
      "training model\n",
      "84/84 [==============================] - 0s 445us/step - loss: 0.1866 - accuracy: 0.9670\n",
      "Test set\n",
      "  Loss: 0.187\n",
      "  Accuracy: 0.967\n"
     ]
    }
   ],
   "source": [
    "run_pipeline('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "loading df\n",
      "training model\n",
      "76/76 [==============================] - 0s 553us/step - loss: 0.1876 - accuracy: 0.9725\n",
      "Test set\n",
      "  Loss: 0.188\n",
      "  Accuracy: 0.973\n"
     ]
    }
   ],
   "source": [
    "run_pipeline('lasbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "loading df\n",
      "training model\n",
      "65/65 [==============================] - 0s 447us/step - loss: 0.1774 - accuracy: 0.9779\n",
      "Test set\n",
      "  Loss: 0.177\n",
      "  Accuracy: 0.978\n"
     ]
    }
   ],
   "source": [
    "run_pipeline('use')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data and use in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_indexes_dict = {\n",
    "  'greeting': 0,\n",
    "  'inform_medicine': 1,\n",
    "  'inform_symptoms': 2,\n",
    "  'request_inform': 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>intent</th>\n",
       "      <th>intent_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meu nariz tá entupido né mas não tá me incomod...</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boa noite, Valéria. Desde sexta que estou com ...</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>estava espirrando muito</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dipirona não vai tratar</td>\n",
       "      <td>inform_medicine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>E como a tossi desaparece? Sem tomar remédio?</td>\n",
       "      <td>request_inform</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>ainda com sensação de fraqueza e cansaço leve ...</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>Há 3 dias começou a tosse</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>So calafrio</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>Mas a garganta continuar com um pouco de pus</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>Estou tomando chá de limão com bicarbonato, es...</td>\n",
       "      <td>inform_medicine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    txt           intent  \\\n",
       "1     Meu nariz tá entupido né mas não tá me incomod...  inform_symptoms   \n",
       "3     Boa noite, Valéria. Desde sexta que estou com ...  inform_symptoms   \n",
       "4                               estava espirrando muito  inform_symptoms   \n",
       "5                               Dipirona não vai tratar  inform_medicine   \n",
       "6         E como a tossi desaparece? Sem tomar remédio?   request_inform   \n",
       "...                                                 ...              ...   \n",
       "1858  ainda com sensação de fraqueza e cansaço leve ...  inform_symptoms   \n",
       "1860                          Há 3 dias começou a tosse  inform_symptoms   \n",
       "1863                                        So calafrio  inform_symptoms   \n",
       "1868       Mas a garganta continuar com um pouco de pus  inform_symptoms   \n",
       "1869  Estou tomando chá de limão com bicarbonato, es...  inform_medicine   \n",
       "\n",
       "      intent_index  \n",
       "1                2  \n",
       "3                2  \n",
       "4                2  \n",
       "5                1  \n",
       "6                3  \n",
       "...            ...  \n",
       "1858             2  \n",
       "1860             2  \n",
       "1863             2  \n",
       "1868             2  \n",
       "1869             1  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anottated_manual_path = fm.filename_from_data_dir('output/patient/manual_label/sentences_with_label_manual.csv')\n",
    "\n",
    "anottated_manual_df = pd.read_csv(anottated_manual_path)\n",
    "\n",
    "data_to_valid = anottated_manual_df[anottated_manual_df['intent'] != 'others'][:1000]\n",
    "\n",
    "data_to_valid['intent_index'] = data_to_valid['intent'].map(intent_indexes_dict)\n",
    "\n",
    "data_to_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inform_symptoms    600\n",
       "request_inform     195\n",
       "greeting           106\n",
       "inform_medicine     99\n",
       "Name: intent, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_valid['intent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_label_manual = data_to_valid['intent_index'].to_numpy()\n",
    "\n",
    "correct_label_manual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df_embeddings(embedding_name, actor='patient'):\n",
    "  df_embeddings = fm.read_json_of_dir(\n",
    "      fm.filename_from_data_dir(\n",
    "          f'embeddings/{embedding_name}/text_emb_{actor}.json'),\n",
    "      lines=True\n",
    "  )\n",
    "\n",
    "  annotated_sentences = pd.read_csv(fm.filename_from_data_dir('output/patient/annotated_sentences.csv'))\n",
    "\n",
    "  annotated_sentences['embeddings'] = df_embeddings['embeddings']\n",
    "\n",
    "  return annotated_sentences[['txt', 'embeddings']]\n",
    "\n",
    "def get_validation_data_with_embeddings(embedding_name):\n",
    "    df_with_embeddings = read_df_embeddings(embedding_name)\n",
    "\n",
    "    df_merged = pd.merge(data_to_valid, df_with_embeddings, on='txt', how='left')\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "def run_validation_pipeline(embedding_name):\n",
    "  print('Loading validation data....')\n",
    "  df_with_embeddings = get_validation_data_with_embeddings(embedding_name)\n",
    "  x_validation = np.array(df_with_embeddings['embeddings'].map(lambda x: np.array(x[0])).to_list())\n",
    "\n",
    "  print(f'The embedding: {embedding_name} has a dimensionality of: {x_validation.shape[1]}')\n",
    "\n",
    "  print('Loading model....')\n",
    "  path_model = fm.filename_from_data_dir(f'output/neural_models/patient/{embedding_name}/model.h5')\n",
    "  model = load_model(path_model)\n",
    "\n",
    "  print('Running pridictions....')\n",
    "  predictions = model.predict(x_validation)\n",
    "  intent_predicteds = np.array([np.argmax(prediction) for prediction in predictions])\n",
    "\n",
    "\n",
    "  correct_predict_manual = np.equal(intent_predicteds, correct_label_manual).sum()\n",
    "  accuracy = correct_predict_manual / len(correct_label_manual)\n",
    "\n",
    "  print(f'\\nThe accuracy is {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: bert_pt has a dimensionality of: 768\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.928\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: flair_pt has a dimensionality of: 4096\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.835\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('flair_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: glove has a dimensionality of: 300\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.702\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: lasbe has a dimensionality of: 768\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.917\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('lasbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: use has a dimensionality of: 512\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.885\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df_embeddings(embedding_name, actor='patient'):\n",
    "  df_embeddings = fm.read_json_of_dir(\n",
    "      fm.filename_from_data_dir(\n",
    "          f'embeddings/{embedding_name}/text_emb_{actor}.json'),\n",
    "      lines=True\n",
    "  )\n",
    "\n",
    "  annotated_sentences = pd.read_csv(fm.filename_from_data_dir('output/patient/annotated_sentences.csv'))\n",
    "\n",
    "  annotated_sentences['embeddings'] = df_embeddings['embeddings']\n",
    "\n",
    "  return annotated_sentences[['txt', 'embeddings']]\n",
    "\n",
    "def get_validation_data_with_embeddings(embedding_name):\n",
    "    df_with_embeddings = read_df_embeddings(embedding_name)\n",
    "\n",
    "    df_merged = pd.merge(data_to_valid, df_with_embeddings, on='txt', how='left')\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "def run_validation_pipeline(embedding_name):\n",
    "  print('Loading validation data....')\n",
    "  df_with_embeddings = get_validation_data_with_embeddings(embedding_name)\n",
    "  x_validation = np.array(df_with_embeddings['embeddings'].map(lambda x: np.array(x[0])).to_list())\n",
    "\n",
    "  print(f'The embedding: {embedding_name} has a dimensionality of: {x_validation.shape[1]}')\n",
    "\n",
    "  print('Loading model....')\n",
    "  path_model = fm.filename_from_data_dir(f'output/neural_models/patient/{embedding_name}/model.h5')\n",
    "  model = load_model(path_model)\n",
    "\n",
    "  print('Running pridictions....')\n",
    "  predictions = model.predict(x_validation)\n",
    "  intent_predicteds = np.array([np.argmax(prediction) for prediction in predictions])\n",
    "\n",
    "\n",
    "  correct_predict_manual = np.equal(intent_predicteds, correct_label_manual).sum()\n",
    "  accuracy = correct_predict_manual / len(correct_label_manual)\n",
    "\n",
    "  print(f'\\nThe accuracy is {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  apply_seed()\n",
    "  print('loading df')\n",
    "  \n",
    "  df = fm.read_annotated_df_with_embeddings(embedding_name)\n",
    "\n",
    "  X = np.array(df['embeddings'].map(lambda x: np.array(x[0])).to_list())\n",
    "  Y = pd.get_dummies(df['intent']).values\n",
    "\n",
    "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/valmir/dev/python/intent_classifier/data/output/patient/k100//annotated_sentences.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/valmir/dev/python/intent_classifier/notebooks/neural_model_sentences.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/valmir/dev/python/intent_classifier/notebooks/neural_model_sentences.ipynb#ch0000024?line=3'>4</a>\u001b[0m variation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mk100\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/valmir/dev/python/intent_classifier/notebooks/neural_model_sentences.ipynb#ch0000024?line=6'>7</a>\u001b[0m file_name \u001b[39m=\u001b[39m fm\u001b[39m.\u001b[39mfilename_from_data_dir(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/valmir/dev/python/intent_classifier/notebooks/neural_model_sentences.ipynb#ch0000024?line=7'>8</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39moutput/\u001b[39m\u001b[39m{\u001b[39;00mactor\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mvariation\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00membedding_name\u001b[39m}\u001b[39;00m\u001b[39m/annotated_sentences.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/valmir/dev/python/intent_classifier/notebooks/neural_model_sentences.ipynb#ch0000024?line=8'>9</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/valmir/dev/python/intent_classifier/notebooks/neural_model_sentences.ipynb#ch0000024?line=10'>11</a>\u001b[0m df_annotated \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(file_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/valmir/dev/python/intent_classifier/notebooks/neural_model_sentences.ipynb#ch0000024?line=12'>13</a>\u001b[0m df_with_embeddings \u001b[39m=\u001b[39m fm\u001b[39m.\u001b[39mread_annotated_df_with_embeddings(embedding_name, variation\u001b[39m=\u001b[39mvariation)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/valmir/dev/python/intent_classifier/notebooks/neural_model_sentences.ipynb#ch0000024?line=14'>15</a>\u001b[0m df_annotated[\u001b[39m'\u001b[39m\u001b[39mtxt\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mcount(), df_with_embeddings[\u001b[39m'\u001b[39m\u001b[39mtxt\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mcount(), df_with_embeddings[df_with_embeddings[\u001b[39m'\u001b[39m\u001b[39membeddings\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misnull()][\u001b[39m'\u001b[39m\u001b[39mtxt\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mcount()\n",
      "File \u001b[0;32m~/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=664'>665</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=665'>666</a>\u001b[0m     dialect,\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=666'>667</a>\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=675'>676</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=676'>677</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=677'>678</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=679'>680</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=571'>572</a>\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=573'>574</a>\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=574'>575</a>\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=576'>577</a>\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=577'>578</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=929'>930</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=931'>932</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=932'>933</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1212'>1213</a>\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1213'>1214</a>\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1214'>1215</a>\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1215'>1216</a>\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1216'>1217</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1217'>1218</a>\u001b[0m     f,\n\u001b[1;32m   <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1218'>1219</a>\u001b[0m     mode,\n\u001b[1;32m   <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1219'>1220</a>\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1220'>1221</a>\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1221'>1222</a>\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1222'>1223</a>\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1223'>1224</a>\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1224'>1225</a>\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1225'>1226</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1226'>1227</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py?line=1227'>1228</a>\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/common.py?line=783'>784</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/common.py?line=784'>785</a>\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/common.py?line=785'>786</a>\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/common.py?line=786'>787</a>\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/common.py?line=787'>788</a>\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/common.py?line=788'>789</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/common.py?line=789'>790</a>\u001b[0m             handle,\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/common.py?line=790'>791</a>\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/common.py?line=791'>792</a>\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/common.py?line=792'>793</a>\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/common.py?line=793'>794</a>\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/common.py?line=794'>795</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/common.py?line=795'>796</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/common.py?line=796'>797</a>\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pandas/io/common.py?line=797'>798</a>\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/valmir/dev/python/intent_classifier/data/output/patient/k100//annotated_sentences.csv'"
     ]
    }
   ],
   "source": [
    "embedding_name = ''\n",
    "actor = 'patient'\n",
    "# variation='without_others_intent/k100_without_sentences_higher_than_median'\n",
    "variation='k100/'\n",
    "    \n",
    "\n",
    "file_name = fm.filename_from_data_dir(\n",
    "        f'output/{actor}/{variation}/{embedding_name}/annotated_sentences.csv'\n",
    "    )\n",
    "\n",
    "df_annotated = pd.read_csv(file_name)\n",
    "\n",
    "df_with_embeddings = fm.read_annotated_df_with_embeddings(embedding_name, variation=variation)\n",
    "\n",
    "df_annotated['txt'].count(), df_with_embeddings['txt'].count(), df_with_embeddings[df_with_embeddings['embeddings'].isnull()]['txt'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[Pará State]Text_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
