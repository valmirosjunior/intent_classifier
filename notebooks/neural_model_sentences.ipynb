{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zL6SjRcWyrkQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 08:50:37.762900: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-22 08:50:37.762914: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import os\n",
    "import random as rn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from src.core import file_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_seed(verbosity=True):\n",
    "  if verbosity:\n",
    "    print('Applying seed')\n",
    "  SEED = 42\n",
    "  os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "  np.random.seed(SEED)\n",
    "  rn.seed(SEED)\n",
    "  tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(embedding_dim, num_labels):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(64, activation='softmax', input_shape=(embedding_dim,)))\n",
    "  model.add(Dropout(0.1))\n",
    "  model.add(Dense(num_labels, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df_data, embedding_name, suffix, actor = 'patient'):\n",
    "  path_output = fm.filename_from_data_dir(f'output/neural_models/{actor}/{embedding_name}/data_{suffix}.csv')\n",
    "  \n",
    "  df_data.drop('embeddings', axis=1).to_csv(path_output, index=False)\n",
    "\n",
    "def prepare_train_test_data(embedding_name, actor='patient'):\n",
    "  df = fm.read_annotated_df_with_embeddings(embedding_name)\n",
    "\n",
    "  df_train, df_test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "  save_df(df_train, embedding_name, suffix='train', actor=actor)\n",
    "  save_df(df_test, embedding_name, suffix='test', actor=actor)\n",
    "\n",
    "  X_train = np.array(df_train['embeddings'].map(lambda x: np.array(x[0])).to_list())\n",
    "  Y_train = pd.get_dummies(df_train['intent']).values\n",
    "\n",
    "  X_test = np.array(df_test['embeddings'].map(lambda x: np.array(x[0])).to_list())\n",
    "  Y_test = pd.get_dummies(df_test['intent']).values\n",
    "\n",
    "  return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(embedding_name, actor='patient'):\n",
    "  apply_seed()\n",
    "  \n",
    "  X_train, X_test, Y_train, Y_test = prepare_train_test_data(embedding_name=embedding_name, actor=actor)\n",
    "\n",
    "  model = build_model(X_train.shape[1], Y_train.shape[1])\n",
    "\n",
    "  print('training model')\n",
    "  history = model.fit(X_train, Y_train, epochs=20, batch_size=64,validation_split=0.1, verbose=0,\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "\n",
    "  accr = model.evaluate(X_test,Y_test)\n",
    "  print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0], accr[1]))\n",
    "  \n",
    "  path_model = fm.filename_from_data_dir(f'output/neural_models/{actor}/{embedding_name}/model.h5')\n",
    "  # print(f'Saving the model at: {path_model}')\n",
    "  model.save(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "training model\n",
      "83/83 [==============================] - 0s 535us/step - loss: 0.2889 - accuracy: 0.9163\n",
      "Test set\n",
      "  Loss: 0.289\n",
      "  Accuracy: 0.916\n"
     ]
    }
   ],
   "source": [
    "run_pipeline('bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "training model\n",
      "83/83 [==============================] - 0s 656us/step - loss: 0.2584 - accuracy: 0.9268\n",
      "Test set\n",
      "  Loss: 0.258\n",
      "  Accuracy: 0.927\n"
     ]
    }
   ],
   "source": [
    "run_pipeline('flair_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "training model\n",
      "84/84 [==============================] - 0s 465us/step - loss: 0.1866 - accuracy: 0.9670\n",
      "Test set\n",
      "  Loss: 0.187\n",
      "  Accuracy: 0.967\n"
     ]
    }
   ],
   "source": [
    "run_pipeline('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "training model\n",
      "76/76 [==============================] - 0s 533us/step - loss: 0.1876 - accuracy: 0.9725\n",
      "Test set\n",
      "  Loss: 0.188\n",
      "  Accuracy: 0.973\n"
     ]
    }
   ],
   "source": [
    "run_pipeline('lasbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "training model\n",
      "65/65 [==============================] - 0s 469us/step - loss: 0.1774 - accuracy: 0.9779\n",
      "Test set\n",
      "  Loss: 0.177\n",
      "  Accuracy: 0.978\n"
     ]
    }
   ],
   "source": [
    "run_pipeline('use')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data and use in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_indexes_dict = {\n",
    "  'greeting': 0,\n",
    "  'inform_medicine': 1,\n",
    "  'inform_symptoms': 2,\n",
    "  'request_inform': 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1049331/1549828853.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_to_valid['intent_index'] = data_to_valid.loc[:,'intent'].map(intent_indexes_dict)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>intent</th>\n",
       "      <th>intent_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tem algum remedio pra tipo aperto no peito</td>\n",
       "      <td>request_inform</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cansada</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Aí  continuo tonando de 6 em 6 horas</td>\n",
       "      <td>inform_medicine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Onde posso fzr</td>\n",
       "      <td>request_inform</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fraqueza,  não estar, falta de at</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>Sucos gelados não pode?</td>\n",
       "      <td>request_inform</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Desde já grata</td>\n",
       "      <td>greeting</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Ele me relatou que os batimentos cardíacos del...</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Melhor q já me atendeu aqui foi vc obg</td>\n",
       "      <td>greeting</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Quero ajuda sim.</td>\n",
       "      <td>request_inform</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   txt           intent  \\\n",
       "5           Tem algum remedio pra tipo aperto no peito   request_inform   \n",
       "9                                              Cansada  inform_symptoms   \n",
       "13                Aí  continuo tonando de 6 em 6 horas  inform_medicine   \n",
       "15                                      Onde posso fzr   request_inform   \n",
       "22                   Fraqueza,  não estar, falta de at  inform_symptoms   \n",
       "..                                                 ...              ...   \n",
       "988                            Sucos gelados não pode?   request_inform   \n",
       "992                                     Desde já grata         greeting   \n",
       "995  Ele me relatou que os batimentos cardíacos del...  inform_symptoms   \n",
       "996             Melhor q já me atendeu aqui foi vc obg         greeting   \n",
       "997                                   Quero ajuda sim.   request_inform   \n",
       "\n",
       "     intent_index  \n",
       "5               3  \n",
       "9               2  \n",
       "13              1  \n",
       "15              3  \n",
       "22              2  \n",
       "..            ...  \n",
       "988             3  \n",
       "992             0  \n",
       "995             2  \n",
       "996             0  \n",
       "997             3  \n",
       "\n",
       "[212 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anottated_manual_path = fm.filename_from_data_dir('output/patient/manual_label/not_used_sentences_with_label_manual.csv')\n",
    "\n",
    "anottated_manual_df = pd.read_csv(anottated_manual_path)\n",
    "\n",
    "data_to_valid = anottated_manual_df.loc[anottated_manual_df['intent'] != 'others']\n",
    "\n",
    "data_to_valid['intent_index'] = data_to_valid.loc[:,'intent'].map(intent_indexes_dict)\n",
    "\n",
    "data_to_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>intent</th>\n",
       "      <th>intent_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sim,Dipirona 1g e vitamina c</td>\n",
       "      <td>inform_medicine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ate hoje nao sinto cheiro de nada ... Por msis...</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A dor já tem uns dois dias que sinto</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Um pouco de coriza</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ok.fico muito agradecida.</td>\n",
       "      <td>greeting</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Tomei hoje, dipirona pela manha e agora as 17:00</td>\n",
       "      <td>inform_medicine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>As vezes há a dificuldade para falar tbm</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Ainda sobre a nimesulida, ele tomou apenas 01 ...</td>\n",
       "      <td>inform_medicine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>No momento o único sintoma que tenho  é a resp...</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Eu to tomando paracetamol  e  limão   alho cha...</td>\n",
       "      <td>inform_medicine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   txt           intent  \\\n",
       "1                         Sim,Dipirona 1g e vitamina c  inform_medicine   \n",
       "2    Ate hoje nao sinto cheiro de nada ... Por msis...  inform_symptoms   \n",
       "5                 A dor já tem uns dois dias que sinto  inform_symptoms   \n",
       "8                                   Um pouco de coriza  inform_symptoms   \n",
       "11                           Ok.fico muito agradecida.         greeting   \n",
       "..                                                 ...              ...   \n",
       "296   Tomei hoje, dipirona pela manha e agora as 17:00  inform_medicine   \n",
       "300           As vezes há a dificuldade para falar tbm  inform_symptoms   \n",
       "301  Ainda sobre a nimesulida, ele tomou apenas 01 ...  inform_medicine   \n",
       "303  No momento o único sintoma que tenho  é a resp...  inform_symptoms   \n",
       "306  Eu to tomando paracetamol  e  limão   alho cha...  inform_medicine   \n",
       "\n",
       "     intent_index  \n",
       "1               1  \n",
       "2               2  \n",
       "5               2  \n",
       "8               2  \n",
       "11              0  \n",
       "..            ...  \n",
       "296             1  \n",
       "300             2  \n",
       "301             1  \n",
       "303             2  \n",
       "306             1  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anottated_manual_path = fm.filename_from_data_dir('output/patient/manual_label/sentences_with_label_manual.csv')\n",
    "anottated_manual_path = fm.filename_from_data_dir('output/patient/manual_label/untrained_sentences_with_label_manual.csv')\n",
    "\n",
    "anottated_manual_df = pd.read_csv(anottated_manual_path)\n",
    "\n",
    "data_to_valid = anottated_manual_df[anottated_manual_df['intent'] != 'others'][:100]\n",
    "\n",
    "data_to_valid['intent_index'] = data_to_valid['intent'].map(intent_indexes_dict)\n",
    "\n",
    "data_to_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_valid = pd.concat(\n",
    "  [data_to_valid[data_to_valid['intent'] ==  intent][:25] for intent in data_to_valid.intent.unique()],\n",
    "  ignore_index=True\n",
    "  )\n",
    "\n",
    "# data_to_valid = data_to_valid[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inform_symptoms    56\n",
       "request_inform     20\n",
       "inform_medicine    14\n",
       "greeting           10\n",
       "Name: intent, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_valid['intent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_label_manual = data_to_valid['intent_index'].to_numpy()\n",
    "\n",
    "correct_label_manual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df_embeddings(embedding_name, actor='patient'):\n",
    "  df_embeddings = fm.read_json_of_dir(\n",
    "      fm.filename_from_data_dir(\n",
    "          f'embeddings/{embedding_name}/text_emb_{actor}.json'),\n",
    "      lines=True\n",
    "  )\n",
    "\n",
    "  annotated_sentences = pd.read_csv(fm.filename_from_data_dir('output/patient/annotated_sentences.csv'))\n",
    "\n",
    "  annotated_sentences['embeddings'] = df_embeddings['embeddings']\n",
    "\n",
    "  return annotated_sentences[['txt', 'embeddings']]\n",
    "\n",
    "def get_validation_data_with_embeddings(embedding_name):\n",
    "    df_with_embeddings = read_df_embeddings(embedding_name)\n",
    "\n",
    "    df_merged = pd.merge(data_to_valid, df_with_embeddings, on='txt', how='left')\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "def run_validation_pipeline(embedding_name):\n",
    "  print('Loading validation data....')\n",
    "  df_with_embeddings = get_validation_data_with_embeddings(embedding_name)\n",
    "  x_validation = np.array(df_with_embeddings['embeddings'].map(lambda x: np.array(x[0])).to_list())\n",
    "\n",
    "  print(f'The embedding: {embedding_name} has a dimensionality of: {x_validation.shape[1]}')\n",
    "\n",
    "  print('Loading model....')\n",
    "  path_model = fm.filename_from_data_dir(f'output/neural_models/patient/{embedding_name}/model.h5')\n",
    "  model = load_model(path_model)\n",
    "\n",
    "  print('Running pridictions....')\n",
    "  predictions = model.predict(x_validation)\n",
    "  intent_predicteds = np.array([np.argmax(prediction) for prediction in predictions])\n",
    "\n",
    "\n",
    "  correct_predict_manual = np.equal(intent_predicteds, correct_label_manual).sum()\n",
    "  accuracy = correct_predict_manual / len(correct_label_manual)\n",
    "\n",
    "  print(f'\\nThe accuracy is {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with not seen data weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: bert_pt has a dimensionality of: 768\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.74\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: flair_pt has a dimensionality of: 4096\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.61\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('flair_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: glove has a dimensionality of: 300\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.36\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: lasbe has a dimensionality of: 768\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.81\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('lasbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: use has a dimensionality of: 512\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.74\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('use')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with not seen data not weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: bert_pt has a dimensionality of: 768\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.84\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: flair_pt has a dimensionality of: 4096\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.71\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('flair_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: glove has a dimensionality of: 300\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.545\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: lasbe has a dimensionality of: 768\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.865\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('lasbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: use has a dimensionality of: 512\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.82\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('use')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### not trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: bert_pt has a dimensionality of: 768\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.89\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: flair_pt has a dimensionality of: 4096\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.83\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('flair_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: glove has a dimensionality of: 300\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.6\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: lasbe has a dimensionality of: 768\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.89\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('lasbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: use has a dimensionality of: 512\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.91\n"
     ]
    }
   ],
   "source": [
    "run_validation_pipeline('use')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### other experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: bert_pt has a dimensionality of: 768\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.928\n"
     ]
    }
   ],
   "source": [
    "# run_validation_pipeline('bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: flair_pt has a dimensionality of: 4096\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.835\n"
     ]
    }
   ],
   "source": [
    "# run_validation_pipeline('flair_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: glove has a dimensionality of: 300\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.702\n"
     ]
    }
   ],
   "source": [
    "# run_validation_pipeline('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: lasbe has a dimensionality of: 768\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.917\n"
     ]
    }
   ],
   "source": [
    "# run_validation_pipeline('lasbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: use has a dimensionality of: 512\n",
      "Loading model....\n",
      "Running pridictions....\n",
      "\n",
      "The accuracy is 0.885\n"
     ]
    }
   ],
   "source": [
    "# run_validation_pipeline('use')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sentence intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fm.read_annotated_df_with_embeddings('bert_pt')\n",
    "\n",
    "data_to_valid[data_to_valid['txt'].isin(df['correct_txt'])]['txt'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fm.read_annotated_df_with_embeddings('flair_pt')\n",
    "\n",
    "data_to_valid[data_to_valid['txt'].isin(df['correct_txt'])]['txt'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fm.read_annotated_df_with_embeddings('glove')\n",
    "\n",
    "data_to_valid[data_to_valid['txt'].isin(df['correct_txt'])]['txt'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fm.read_annotated_df_with_embeddings('lasbe')\n",
    "\n",
    "data_to_valid[data_to_valid['txt'].isin(df['correct_txt'])]['txt'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fm.read_annotated_df_with_embeddings('use')\n",
    "\n",
    "data_to_valid[data_to_valid['txt'].isin(df['correct_txt'])]['txt'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_data_intersection(embedding_name):\n",
    "  apply_seed(verbosity=False)\n",
    "  df = fm.read_annotated_df_with_embeddings(embedding_name)\n",
    "\n",
    "  X = np.array(df['embeddings'].map(lambda x: np.array(x[0])).to_list())\n",
    "  Y = pd.get_dummies(df['intent']).values\n",
    "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "  data = df[['correct_txt', 'intent', 'embeddings']]\n",
    "\n",
    "  data_train, data_test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "  if not (X_train == np.array(data_train['embeddings'].map(lambda x: np.array(x[0])).to_list())).all():\n",
    "    print('The train data it isn\\'t equal...')\n",
    "\n",
    "  count_examples_in_train_test_data = data_to_valid[data_to_valid['txt'].isin(df['correct_txt'])]['txt'].count()\n",
    "  count_examples_in_train_data = data_to_valid[data_to_valid['txt'].isin(data_train['correct_txt'])]['txt'].count()\n",
    "\n",
    "  # count_examples_in_data = data_to_valid[data_to_valid['txt'].isin(df['correct_txt'])]['txt'].count()\n",
    "\n",
    "  clustering_labels = data_train[data_train['correct_txt'].isin(data_to_valid['txt'])].sort_values('correct_txt')['intent'].to_numpy()\n",
    "\n",
    "  manual_labels = data_to_valid[data_to_valid['txt'].isin(data_train['correct_txt'])].sort_values('txt')['intent'].to_numpy()\n",
    "\n",
    "  count_correct_labels = np.equal(clustering_labels, manual_labels).sum()\n",
    "\n",
    "  print(f'The data has {len(X)} sentences and {len(X_train)} examples in the train data')\n",
    "  print(f'The total of sentences of manual anotation in the train/test data is {count_examples_in_train_test_data}')\n",
    "  print(f'There is {count_examples_in_train_data} examples of manual anotation in the train data')\n",
    "  print(f'There is {count_correct_labels} examples of manual anotation with correct label in the train data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 8837 sentences and 6185 examples in the train data\n",
      "The total of sentences of manual anotation in the train/test data is 479\n",
      "There is 317 examples of manual anotation in the train data\n",
      "There is 298 examples of manual anotation with correct label in the train data\n"
     ]
    }
   ],
   "source": [
    "describe_data_intersection('bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 8840 sentences and 6188 examples in the train data\n",
      "The total of sentences of manual anotation in the train/test data is 448\n",
      "There is 314 examples of manual anotation in the train data\n",
      "There is 278 examples of manual anotation with correct label in the train data\n"
     ]
    }
   ],
   "source": [
    "describe_data_intersection('flair_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 8900 sentences and 6230 examples in the train data\n",
      "The total of sentences of manual anotation in the train/test data is 403\n",
      "There is 282 examples of manual anotation in the train data\n",
      "There is 225 examples of manual anotation with correct label in the train data\n"
     ]
    }
   ],
   "source": [
    "describe_data_intersection('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 8007 sentences and 5604 examples in the train data\n",
      "The total of sentences of manual anotation in the train/test data is 450\n",
      "There is 312 examples of manual anotation in the train data\n",
      "There is 290 examples of manual anotation with correct label in the train data\n"
     ]
    }
   ],
   "source": [
    "describe_data_intersection('lasbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 6928 sentences and 4849 examples in the train data\n",
      "The total of sentences of manual anotation in the train/test data is 382\n",
      "There is 277 examples of manual anotation in the train data\n",
      "There is 257 examples of manual anotation with correct label in the train data\n"
     ]
    }
   ],
   "source": [
    "describe_data_intersection('use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_annotated[df_annotated['txt'].str.contains('\\'') | df_annotated['txt'].str.contains('\"')]['txt'].to_numpy()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[Pará State]Text_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
