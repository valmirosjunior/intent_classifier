{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:14:20.840365: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-03-05 00:14:20.840380: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[nltk_data] Downloading package stopwords to /home/valmir/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from src.bertopic.data_helper import DataHelper\n",
    "from src.bertopic.neural_model import NeuralModel\n",
    "from src.bertopic.word_cloud_helper import WordCloudHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_name = 'lasbe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh = WordCloudHelper(embedding_name)\n",
    "# wh.generate_word_cloud(0)\n",
    "# wh.generate_word_cloud(1)\n",
    "# wh.generate_word_cloud(2)\n",
    "# wh.generate_word_cloud(3)\n",
    "# wh.generate_word_cloud(4)\n",
    "# wh.generate_word_cloud(5)\n",
    "# wh.generate_word_cloud(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total of sentences is: 26754\n",
      "The total of topics is: 346\n",
      "outliers, has 1 topics, and 10944 sentences\n",
      "inform_symptoms, has 89 topics, and 4893 sentences\n",
      "others, has 160 topics, and 6975 sentences\n",
      "greeting, has 36 topics, and 1388 sentences\n",
      "request_inform, has 46 topics, and 1658 sentences\n",
      "inform_medicine, has 14 topics, and 896 sentences\n"
     ]
    }
   ],
   "source": [
    "wh.describe_intents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wh.doc_info['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wh.generate_word_cloud(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh.anottate_intents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intents: ['others' 'outliers' 'request_inform' 'greeting' 'inform_symptoms'\n",
      " 'inform_medicine']\n",
      "last indnex: 344\n"
     ]
    }
   ],
   "source": [
    "wh.check_intents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Probability</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5213.000000</td>\n",
       "      <td>5213.000000</td>\n",
       "      <td>5213.000000</td>\n",
       "      <td>5213.000000</td>\n",
       "      <td>5213.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13270.512565</td>\n",
       "      <td>13270.512565</td>\n",
       "      <td>85.299827</td>\n",
       "      <td>0.970205</td>\n",
       "      <td>85.299827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7818.706396</td>\n",
       "      <td>7818.706396</td>\n",
       "      <td>97.600768</td>\n",
       "      <td>0.084526</td>\n",
       "      <td>97.600768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273862</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6412.000000</td>\n",
       "      <td>6412.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13125.000000</td>\n",
       "      <td>13125.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20066.000000</td>\n",
       "      <td>20066.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26749.000000</td>\n",
       "      <td>26749.000000</td>\n",
       "      <td>343.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>343.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1    Unnamed: 0        Topic  Probability        label\n",
       "count   5213.000000   5213.000000  5213.000000  5213.000000  5213.000000\n",
       "mean   13270.512565  13270.512565    85.299827     0.970205    85.299827\n",
       "std     7818.706396   7818.706396    97.600768     0.084526    97.600768\n",
       "min        6.000000      6.000000     0.000000     0.273862     0.000000\n",
       "25%     6412.000000   6412.000000    12.000000     1.000000    12.000000\n",
       "50%    13125.000000  13125.000000    37.000000     1.000000    37.000000\n",
       "75%    20066.000000  20066.000000   139.000000     1.000000   139.000000\n",
       "max    26749.000000  26749.000000   343.000000     1.000000   343.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dh = DataHelper(embedding_name=embedding_name)\n",
    "\n",
    "dh.save_variation(variation='without_outliers', measure='lower_bound')\n",
    "dh.save_variation(variation='without_sentences_higher_than_median', measure='med')[1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_model = NeuralModel(embedding_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "Split data for variation: without_sentences_higher_than_median/\n",
      "nan values: 34     Isso também influencia em eu ser \"imune\" aos s...\n",
      "369    Não é bem uma \" falta de ar\" eu consigo puxar ...\n",
      "Name: txt, dtype: object\n",
      "The total of sentences is: 5211\n",
      "The total of sentences after remove validation is: 5083\n",
      "Build Model...\n",
      "training model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-05 00:14:49.369638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-05 00:14:49.369951: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-03-05 00:14:49.369984: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-03-05 00:14:49.370011: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-03-05 00:14:49.370036: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-03-05 00:14:49.370061: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2024-03-05 00:14:49.370089: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2024-03-05 00:14:49.370124: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-03-05 00:14:49.370156: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-03-05 00:14:49.370162: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-03-05 00:14:49.370366: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Model...\n",
      "get metrics\n",
      "{\n",
      "    \"accuracy\": 0.9718032786885246,\n",
      "    \"simples_accuracy\": 0.9718032786885246,\n",
      "    \"matthews_corrcoef\": 0.9525785122991807,\n",
      "    \"weighted\": {\n",
      "        \"precision\": 0.9720458631834047,\n",
      "        \"recall\": 0.9718032786885246,\n",
      "        \"f1\": 0.9717489152530695\n",
      "    },\n",
      "    \"macro\": {\n",
      "        \"precision\": 0.9713120365238342,\n",
      "        \"recall\": 0.9571757263339915,\n",
      "        \"f1\": 0.9637656532324308\n",
      "    },\n",
      "    \"micro\": {\n",
      "        \"precision\": 0.9718032786885246,\n",
      "        \"recall\": 0.9718032786885246,\n",
      "        \"f1\": 0.9718032786885246\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "neural_model.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "nan values: Series([], Name: txt, dtype: object)\n",
      "The embedding: lasbe has a dimensionality of: 768\n",
      "Loading model....\n",
      "Running pridictions....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9696969696969697,\n",
       " 'simples_accuracy': 0.9696969696969697,\n",
       " 'matthews_corrcoef': 0.9467187001646706,\n",
       " 'weighted': {'precision': 0.972124246216862,\n",
       "  'recall': 0.9696969696969697,\n",
       "  'f1': 0.9685785720976336},\n",
       " 'macro': {'precision': 0.9479036295369212,\n",
       "  'recall': 0.9476744186046512,\n",
       "  'f1': 0.94253161833807},\n",
       " 'micro': {'precision': 0.9696969696969697,\n",
       "  'recall': 0.9696969696969697,\n",
       "  'f1': 0.9696969696969697}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_model.run_validation_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da386d383b1a4f2ab977ab0cc371ee70ac9bd2160da3f0bf5cca7f94d497a6a3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
