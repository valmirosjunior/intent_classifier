{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zL6SjRcWyrkQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import os\n",
    "import random as rn\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from src.core import file_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def apply_seed(verbosity=True):\n",
    "  if verbosity:\n",
    "    print('Applying seed')\n",
    "  SEED = 42\n",
    "  os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "  np.random.seed(SEED)\n",
    "  rn.seed(SEED)\n",
    "  tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(embedding_dim, num_labels):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(64, activation='softmax', input_shape=(embedding_dim,)))\n",
    "  model.add(Dropout(0.1))\n",
    "  model.add(Dense(num_labels, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_df(df_data, embedding_name, suffix, actor = 'patient'):\n",
    "  path_output = fm.filename_from_data_dir(f'output/neural_models/{actor}/{embedding_name}/data_{suffix}.csv')\n",
    "  \n",
    "  df_data.drop('embeddings', axis=1).to_csv(path_output, index=False)\n",
    "\n",
    "def prepare_train_test_data(embedding_name, actor='patient'):\n",
    "  df = fm.read_annotated_df_with_embeddings(embedding_name)\n",
    "\n",
    "  df_train, df_test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "  save_df(df_train, embedding_name, suffix='train', actor=actor)\n",
    "  save_df(df_test, embedding_name, suffix='test', actor=actor)\n",
    "\n",
    "  X_train = np.array(df_train['embeddings'].map(lambda x: np.array(x[0])).to_list())\n",
    "  Y_train = pd.get_dummies(df_train['intent']).values\n",
    "\n",
    "  X_test = np.array(df_test['embeddings'].map(lambda x: np.array(x[0])).to_list())\n",
    "  Y_test = pd.get_dummies(df_test['intent']).values\n",
    "\n",
    "  labels = np.array(list(range(0, pd.get_dummies(df['intent']).values.shape[1])))\n",
    "\n",
    "  return X_train, X_test, Y_train, Y_test, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, labels):\n",
    "  accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "  precision = metrics.precision_score(y_true, y_pred, average='weighted', labels=labels)\n",
    "  recall = metrics.recall_score(y_true, y_pred, average='weighted', labels=labels)\n",
    "  f1 = metrics.f1_score(y_true, y_pred, average='weighted', labels=labels)\n",
    "\n",
    "  return {\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1,\n",
    "    'accuracy': accuracy\n",
    "  }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_pipeline(embedding_name, actor='patient'):\n",
    "  apply_seed()\n",
    "  \n",
    "  X_train, X_test, Y_train, Y_test, labels = prepare_train_test_data(embedding_name=embedding_name, actor=actor)\n",
    "\n",
    "  model = build_model(X_train.shape[1], Y_train.shape[1])\n",
    "\n",
    "  print('training model')\n",
    "  history = model.fit(X_train, Y_train, epochs=20, batch_size=64,validation_split=0.1, verbose=0,\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "\n",
    "\n",
    "  path_model = fm.filename_from_data_dir(f'output/neural_models/{actor}/{embedding_name}/model.h5')\n",
    "  # print(f'Saving the model at: {path_model}')\n",
    "  model.save(path_model)\n",
    "\n",
    "  # accr = model.evaluate(X_test,Y_test)\n",
    "  # print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0], accr[1]))\n",
    "\n",
    "  model_pred = model.predict(X_test)\n",
    "\n",
    "  y_true = np.array([np.argmax(label) for label in Y_test])\n",
    "  y_pred = np.array([np.argmax(prediction) for prediction in model_pred])\n",
    "\n",
    "  return compute_metrics(y_true, y_pred, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "training model\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'precision': 0.9153824130442597,\n 'recall': 0.916289592760181,\n 'f1': 0.9152942105448022,\n 'accuracy': 0.916289592760181}"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pipeline('bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "training model\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'precision': 0.9277105620580804,\n 'recall': 0.9268476621417798,\n 'f1': 0.9235201521431274,\n 'accuracy': 0.9268476621417798}"
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pipeline('flair_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "training model\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'precision': 0.9672050536104059,\n 'recall': 0.9670411985018726,\n 'f1': 0.9660648683486441,\n 'accuracy': 0.9670411985018726}"
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pipeline('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "training model\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'precision': 0.9724620632678047,\n 'recall': 0.9725343320848939,\n 'f1': 0.9724436745946483,\n 'accuracy': 0.9725343320848939}"
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pipeline('lasbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "training model\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'precision': 0.977776164703149,\n 'recall': 0.9778739778739779,\n 'f1': 0.9778047029432841,\n 'accuracy': 0.9778739778739779}"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pipeline('use')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Read data and use in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "def get_data_to_valid(variation='not_used_sentences_with_label_manual'):\n",
    "  annotated_manual_path = fm.filename_from_data_dir(f'output/patient/manual_label/{variation}.csv')\n",
    "\n",
    "  annotated_manual_df = pd.read_csv(annotated_manual_path)\n",
    "\n",
    "  annotated_manual_df.loc[:,'intent_index'] = annotated_manual_df.loc[:,'intent'].map(intent_indexes_dict)\n",
    "\n",
    "  data = annotated_manual_df.loc[annotated_manual_df['intent'] != 'others']\n",
    "\n",
    "  return data\n",
    "\n",
    "def get_weighted_data(df_data, length_for_intent = 25):\n",
    "  return  pd.concat(\n",
    "    [df_data[df_data['intent'] ==  intent][:length_for_intent] for intent in df_data.intent.unique()],\n",
    "    ignore_index=True\n",
    "  )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_df_embeddings(embedding_name, actor='patient'):\n",
    "  df_embeddings = fm.read_json_of_dir(\n",
    "      fm.filename_from_data_dir(\n",
    "          f'embeddings/{embedding_name}/text_emb_{actor}.json'),\n",
    "      lines=True\n",
    "  )\n",
    "\n",
    "  annotated_sentences = pd.read_csv(fm.filename_from_data_dir('output/patient/annotated_sentences.csv'))\n",
    "\n",
    "  annotated_sentences['embeddings'] = df_embeddings['embeddings']\n",
    "\n",
    "  return annotated_sentences[['txt', 'embeddings']]\n",
    "\n",
    "def get_validation_data_with_embeddings(embedding_name):\n",
    "    df_with_embeddings = read_df_embeddings(embedding_name)\n",
    "\n",
    "    df_merged = pd.merge(data_to_valid, df_with_embeddings, on='txt', how='left')\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "def run_validation_pipeline(embedding_name, correct_labels, labels):\n",
    "  print('Loading validation data....')\n",
    "  df_with_embeddings = get_validation_data_with_embeddings(embedding_name)\n",
    "  x_validation = np.array(df_with_embeddings['embeddings'].map(lambda x: np.array(x[0])).to_list())\n",
    "\n",
    "  print(f'The embedding: {embedding_name} has a dimensionality of: {x_validation.shape[1]}')\n",
    "\n",
    "  print('Loading model....')\n",
    "  path_model = fm.filename_from_data_dir(f'output/neural_models/patient/{embedding_name}/model.h5')\n",
    "  model = load_model(path_model)\n",
    "\n",
    "  print('Running predictions....')\n",
    "  predictions = model.predict(x_validation)\n",
    "  intent_predicts = np.array([np.argmax(prediction) for prediction in predictions])\n",
    "\n",
    "  return compute_metrics(correct_labels, intent_predicts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "intent_indexes_dict = {\n",
    "  'greeting': 0,\n",
    "  'inform_medicine': 1,\n",
    "  'inform_symptoms': 2,\n",
    "  'request_inform': 3,\n",
    "}\n",
    "\n",
    "intent_indexes = np.array(list(intent_indexes_dict.values()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### with not seen data weighted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inform_symptoms    102\n",
      "request_inform      47\n",
      "inform_medicine     33\n",
      "greeting            30\n",
      "Name: intent, dtype: int64\n",
      "\n",
      "Data weighted:\n",
      "request_inform     30\n",
      "inform_symptoms    30\n",
      "inform_medicine    30\n",
      "greeting           30\n",
      "Name: intent, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": "(120,)"
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_valid = get_data_to_valid()\n",
    "print(data_to_valid['intent'].value_counts())\n",
    "\n",
    "print('\\nData weighted:')\n",
    "data_to_valid = get_weighted_data(data_to_valid, 30)\n",
    "print(data_to_valid['intent'].value_counts())\n",
    "\n",
    "correct_labels = data_to_valid['intent_index'].to_numpy()\n",
    "\n",
    "correct_labels.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: bert_pt has a dimensionality of: 768\n",
      "Loading model....\n",
      "Running predictions....\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'precision': 0.8372586532963892,\n 'recall': 0.7583333333333333,\n 'f1': 0.7502747620015597,\n 'accuracy': 0.7583333333333333}"
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_validation_pipeline('bert_pt', correct_labels, intent_indexes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: flair_pt has a dimensionality of: 4096\n",
      "Loading model....\n",
      "Running predictions....\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'precision': 0.8138513513513513,\n 'recall': 0.6083333333333333,\n 'f1': 0.557632528761561,\n 'accuracy': 0.6083333333333333}"
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_validation_pipeline('flair_pt', correct_labels, intent_indexes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: glove has a dimensionality of: 300\n",
      "Loading model....\n",
      "Running predictions....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'precision': 0.48044871794871796,\n 'recall': 0.35833333333333334,\n 'f1': 0.28138474295190713,\n 'accuracy': 0.35833333333333334}"
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_validation_pipeline('glove', correct_labels, intent_indexes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: lasbe has a dimensionality of: 768\n",
      "Loading model....\n",
      "Running predictions....\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'precision': 0.8605144855144855,\n 'recall': 0.825,\n 'f1': 0.8289745552676587,\n 'accuracy': 0.825}"
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_validation_pipeline('lasbe', correct_labels, intent_indexes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: use has a dimensionality of: 512\n",
      "Loading model....\n",
      "Running predictions....\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'precision': 0.8415325670498084,\n 'recall': 0.7416666666666667,\n 'f1': 0.7491805813234386,\n 'accuracy': 0.7416666666666667}"
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_validation_pipeline('use', correct_labels, intent_indexes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### with not seen data weighted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_validation_pipeline('bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_validation_pipeline('flair_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_validation_pipeline('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_validation_pipeline('lasbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_validation_pipeline('use')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### with not seen data not weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_validation_pipeline('bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_validation_pipeline('flair_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_validation_pipeline('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_validation_pipeline('lasbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_validation_pipeline('use')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### not trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_validation_pipeline('bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_validation_pipeline('flair_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_validation_pipeline('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_validation_pipeline('lasbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_validation_pipeline('use')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### other experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# run_validation_pipeline('bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# run_validation_pipeline('flair_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# run_validation_pipeline('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# run_validation_pipeline('lasbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# run_validation_pipeline('use')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### sentence intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = fm.read_annotated_df_with_embeddings('bert_pt')\n",
    "\n",
    "data_to_valid[data_to_valid['txt'].isin(df['correct_txt'])]['txt'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = fm.read_annotated_df_with_embeddings('flair_pt')\n",
    "\n",
    "data_to_valid[data_to_valid['txt'].isin(df['correct_txt'])]['txt'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = fm.read_annotated_df_with_embeddings('glove')\n",
    "\n",
    "data_to_valid[data_to_valid['txt'].isin(df['correct_txt'])]['txt'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = fm.read_annotated_df_with_embeddings('lasbe')\n",
    "\n",
    "data_to_valid[data_to_valid['txt'].isin(df['correct_txt'])]['txt'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = fm.read_annotated_df_with_embeddings('use')\n",
    "\n",
    "data_to_valid[data_to_valid['txt'].isin(df['correct_txt'])]['txt'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def describe_data_intersection(embedding_name):\n",
    "  apply_seed(verbosity=False)\n",
    "  df = fm.read_annotated_df_with_embeddings(embedding_name)\n",
    "\n",
    "  X = np.array(df['embeddings'].map(lambda x: np.array(x[0])).to_list())\n",
    "  Y = pd.get_dummies(df['intent']).values\n",
    "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "  data = df[['correct_txt', 'intent', 'embeddings']]\n",
    "\n",
    "  data_train, data_test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "  if not (X_train == np.array(data_train['embeddings'].map(lambda x: np.array(x[0])).to_list())).all():\n",
    "    print('The train data it isn\\'t equal...')\n",
    "\n",
    "  count_examples_in_train_test_data = data_to_valid[data_to_valid['txt'].isin(df['correct_txt'])]['txt'].count()\n",
    "  count_examples_in_train_data = data_to_valid[data_to_valid['txt'].isin(data_train['correct_txt'])]['txt'].count()\n",
    "\n",
    "  # count_examples_in_data = data_to_valid[data_to_valid['txt'].isin(df['correct_txt'])]['txt'].count()\n",
    "\n",
    "  clustering_labels = data_train[data_train['correct_txt'].isin(data_to_valid['txt'])].sort_values('correct_txt')['intent'].to_numpy()\n",
    "\n",
    "  manual_labels = data_to_valid[data_to_valid['txt'].isin(data_train['correct_txt'])].sort_values('txt')['intent'].to_numpy()\n",
    "\n",
    "  count_correct_labels = np.equal(clustering_labels, manual_labels).sum()\n",
    "\n",
    "  print(f'The data has {len(X)} sentences and {len(X_train)} examples in the train data')\n",
    "  print(f'The total of sentences of manual anotation in the train/test data is {count_examples_in_train_test_data}')\n",
    "  print(f'There is {count_examples_in_train_data} examples of manual anotation in the train data')\n",
    "  print(f'There is {count_correct_labels} examples of manual anotation with correct label in the train data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "describe_data_intersection('bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "describe_data_intersection('flair_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "describe_data_intersection('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "describe_data_intersection('lasbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "describe_data_intersection('use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df_annotated[df_annotated['txt'].str.contains('\\'') | df_annotated['txt'].str.contains('\"')]['txt'].to_numpy()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[Par√° State]Text_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}