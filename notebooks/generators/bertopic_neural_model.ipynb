{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zL6SjRcWyrkQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 22:46:12.670124: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-07 22:46:12.670138: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from src.classifier import NeuralModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "training model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9250585480093677,\n",
       " 'simples_accuracy': 0.9250585480093677,\n",
       " 'matthews_corrcoef': 0.8676562487532198,\n",
       " 'weighted': {'precision': 0.9266943830209318,\n",
       "  'recall': 0.9250585480093677,\n",
       "  'f1': 0.9257570013048291},\n",
       " 'macro': {'precision': 0.8911996758734892,\n",
       "  'recall': 0.9000675763540181,\n",
       "  'f1': 0.8953974304225556},\n",
       " 'micro': {'precision': 0.9250585480093677,\n",
       "  'recall': 0.9250585480093677,\n",
       "  'f1': 0.9250585480093677}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeuralModel().run_pipeline('bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "training model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9449648711943794,\n",
       " 'simples_accuracy': 0.9449648711943794,\n",
       " 'matthews_corrcoef': 0.8823826877697872,\n",
       " 'weighted': {'precision': 0.9444250781860608,\n",
       "  'recall': 0.9449648711943794,\n",
       "  'f1': 0.9445510816009661},\n",
       " 'macro': {'precision': 0.9285383224000596,\n",
       "  'recall': 0.9150405153373703,\n",
       "  'f1': 0.9215627178033192},\n",
       " 'micro': {'precision': 0.9449648711943794,\n",
       "  'recall': 0.9449648711943794,\n",
       "  'f1': 0.9449648711943794}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pipeline('flair_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "training model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9697674418604652,\n",
       " 'simples_accuracy': 0.9697674418604652,\n",
       " 'matthews_corrcoef': 0.9116203903783816,\n",
       " 'weighted': {'precision': 0.9693379184078887,\n",
       "  'recall': 0.9697674418604652,\n",
       "  'f1': 0.9694404573018798},\n",
       " 'macro': {'precision': 0.9306607094417924,\n",
       "  'recall': 0.9189439448998844,\n",
       "  'f1': 0.9243500933711979},\n",
       " 'micro': {'precision': 0.9697674418604652,\n",
       "  'recall': 0.9697674418604652,\n",
       "  'f1': 0.9697674418604652}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pipeline('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "training model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9749243406830955,\n",
       " 'simples_accuracy': 0.9749243406830955,\n",
       " 'matthews_corrcoef': 0.9582058284470578,\n",
       " 'weighted': {'precision': 0.9749130019606257,\n",
       "  'recall': 0.9749243406830955,\n",
       "  'f1': 0.9748293045276569},\n",
       " 'macro': {'precision': 0.9721729522168296,\n",
       "  'recall': 0.9676287186967907,\n",
       "  'f1': 0.9697473720276892},\n",
       " 'micro': {'precision': 0.9749243406830955,\n",
       "  'recall': 0.9749243406830955,\n",
       "  'f1': 0.9749243406830955}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pipeline('lasbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seed\n",
      "training model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.987430869783811,\n",
       " 'simples_accuracy': 0.987430869783811,\n",
       " 'matthews_corrcoef': 0.9791807803260882,\n",
       " 'weighted': {'precision': 0.9874407591528097,\n",
       "  'recall': 0.987430869783811,\n",
       "  'f1': 0.9874338832300075},\n",
       " 'macro': {'precision': 0.9845783095847035,\n",
       "  'recall': 0.9842937950602118,\n",
       "  'f1': 0.984433295355355},\n",
       " 'micro': {'precision': 0.987430869783811,\n",
       "  'recall': 0.987430869783811,\n",
       "  'f1': 0.987430869783811}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_pipeline('use')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data and use in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_indexes_dict = {\n",
    "  'greeting': 0,\n",
    "  'inform_medicine': 1,\n",
    "  'inform_symptoms': 2,\n",
    "  'request_inform': 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>intent</th>\n",
       "      <th>doubt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Não faço uso de remédio. Estou tomando devido ...</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>/inform_symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>182</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      txt           intent  \\\n",
       "count                                                 300              300   \n",
       "unique                                                300                5   \n",
       "top     Não faço uso de remédio. Estou tomando devido ...  inform_symptoms   \n",
       "freq                                                    1              182   \n",
       "\n",
       "                   doubt  \n",
       "count                 15  \n",
       "unique                 5  \n",
       "top     /inform_symptoms  \n",
       "freq                   7  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anottated_manual_path = fm.filename_from_data_dir( f'output/patient/{variation}/intersection_300_sentences_with_label.csv')\n",
    "\n",
    "anottated_manual_df = pd.read_csv(anottated_manual_path)\n",
    "\n",
    "anottated_manual_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inform_symptoms    182\n",
       "greeting            58\n",
       "request_inform      43\n",
       "inform_medicine     14\n",
       "others               3\n",
       "Name: intent, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anottated_manual_df['intent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_274308/1029788609.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_to_valid['intent_index'] = data_to_valid.loc[:,'intent'].map(intent_indexes_dict)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>intent</th>\n",
       "      <th>doubt</th>\n",
       "      <th>intent_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Não faço uso de remédio. Estou tomando devido ...</td>\n",
       "      <td>inform_medicine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O que vc me aconselha?</td>\n",
       "      <td>request_inform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Não sinto gosto e  nem cheiro</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dor de cabeça e dor garganta</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Só hoje estou sentindo dificuldade pra respirar</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Dor no corpo já tive febre estou com diarreia ...</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Boa tarde, olha eu nao tive mais febre porém h...</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>E só sinto falta de ar qdo me dá crise de tosse</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Só dor no corpo e na cabeça</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Mas meu nariz não tá entupido</td>\n",
       "      <td>inform_symptoms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   txt           intent doubt  \\\n",
       "0    Não faço uso de remédio. Estou tomando devido ...  inform_medicine   NaN   \n",
       "1                               O que vc me aconselha?   request_inform   NaN   \n",
       "2                        Não sinto gosto e  nem cheiro  inform_symptoms   NaN   \n",
       "3                         Dor de cabeça e dor garganta  inform_symptoms   NaN   \n",
       "4      Só hoje estou sentindo dificuldade pra respirar  inform_symptoms   NaN   \n",
       "..                                                 ...              ...   ...   \n",
       "295  Dor no corpo já tive febre estou com diarreia ...  inform_symptoms   NaN   \n",
       "296  Boa tarde, olha eu nao tive mais febre porém h...  inform_symptoms   NaN   \n",
       "297    E só sinto falta de ar qdo me dá crise de tosse  inform_symptoms   NaN   \n",
       "298                        Só dor no corpo e na cabeça  inform_symptoms   NaN   \n",
       "299                      Mas meu nariz não tá entupido  inform_symptoms   NaN   \n",
       "\n",
       "     intent_index  \n",
       "0               1  \n",
       "1               3  \n",
       "2               2  \n",
       "3               2  \n",
       "4               2  \n",
       "..            ...  \n",
       "295             2  \n",
       "296             2  \n",
       "297             2  \n",
       "298             2  \n",
       "299             2  \n",
       "\n",
       "[297 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_valid = anottated_manual_df.loc[anottated_manual_df['intent'] != 'others']\n",
    "\n",
    "data_to_valid['intent_index'] = data_to_valid.loc[:,'intent'].map(intent_indexes_dict)\n",
    "\n",
    "data_to_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anottated_manual_path = fm.filename_from_data_dir('output/patient/manual_label/sentences_with_label_manual.csv')\n",
    "# anottated_manual_path = fm.filename_from_data_dir('output/patient/manual_label/untrained_sentences_with_label_manual.csv')\n",
    "\n",
    "# anottated_manual_df = pd.read_csv(anottated_manual_path)\n",
    "\n",
    "# data_to_valid = anottated_manual_df[anottated_manual_df['intent'] != 'others'][:100]\n",
    "\n",
    "# data_to_valid['intent_index'] = data_to_valid['intent'].map(intent_indexes_dict)\n",
    "\n",
    "# data_to_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_to_valid = pd.concat(\n",
    "#   [data_to_valid[data_to_valid['intent'] ==  intent][:25] for intent in data_to_valid.intent.unique()],\n",
    "#   ignore_index=True\n",
    "#   )\n",
    "\n",
    "# data_to_valid = data_to_valid[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inform_symptoms    182\n",
       "greeting            58\n",
       "request_inform      43\n",
       "inform_medicine     14\n",
       "Name: intent, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_valid['intent'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_data_with_embeddings(embedding_name):\n",
    "    df_with_embeddings = fm.read_annotated_df_with_embeddings(embedding_name, variation=None)[['txt', 'embeddings']]\n",
    "\n",
    "    df_merged = pd.merge(data_to_valid, df_with_embeddings, on='txt', how='left')\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "def run_validation_pipeline(embedding_name):\n",
    "  print('Loading validation data....')\n",
    "  df_with_embeddings = get_validation_data_with_embeddings(embedding_name)\n",
    "  x_validation = np.array(df_with_embeddings['embeddings'].map(lambda x: np.array(x[0])).to_list())\n",
    "\n",
    "  print(f'The embedding: {embedding_name} has a dimensionality of: {x_validation.shape[1]}')\n",
    "\n",
    "  print('Loading model....')\n",
    "  path_model = fm.filename_from_data_dir(f'output/neural_models/patient/{embedding_name}/model.h5')\n",
    "  model = load_model(path_model)\n",
    "\n",
    "  print('Running pridictions....')\n",
    "  predictions = model.predict(x_validation)\n",
    "  \n",
    "  y_true = data_to_valid['intent_index'].to_numpy()\n",
    "  y_pred = np.array([np.argmax(prediction) for prediction in predictions])\n",
    "  labels = np.array(list(intent_indexes_dict.values()))\n",
    "  \n",
    "  return get_metrics_results(y_true, y_pred, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: bert_pt has a dimensionality of: 768\n",
      "Loading model....\n",
      "Running pridictions....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9528619528619529,\n",
       " 'simples_accuracy': 0.9528619528619529,\n",
       " 'matthews_corrcoef': 0.9158426669387549,\n",
       " 'weighted': {'precision': 0.9538439955106622,\n",
       "  'recall': 0.9528619528619529,\n",
       "  'f1': 0.9513338051662472},\n",
       " 'macro': {'precision': 0.9427083333333334,\n",
       "  'recall': 0.8793125479171991,\n",
       "  'f1': 0.9073083778966132},\n",
       " 'micro': {'precision': 0.9528619528619529,\n",
       "  'recall': 0.9528619528619529,\n",
       "  'f1': 0.9528619528619529}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_validation_pipeline('bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: flair_pt has a dimensionality of: 4096\n",
      "Loading model....\n",
      "Running pridictions....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9629629629629629,\n",
       " 'simples_accuracy': 0.9629629629629629,\n",
       " 'matthews_corrcoef': 0.934126558005674,\n",
       " 'weighted': {'precision': 0.9638948139529874,\n",
       "  'recall': 0.9629629629629629,\n",
       "  'f1': 0.9618082509113152},\n",
       " 'macro': {'precision': 0.9799665503199535,\n",
       "  'recall': 0.9164004600051112,\n",
       "  'f1': 0.9449155639555069},\n",
       " 'micro': {'precision': 0.9629629629629629,\n",
       "  'recall': 0.9629629629629629,\n",
       "  'f1': 0.9629629629629629}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_validation_pipeline('flair_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: glove has a dimensionality of: 300\n",
      "Loading model....\n",
      "Running pridictions....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8653198653198653,\n",
       " 'simples_accuracy': 0.8653198653198653,\n",
       " 'matthews_corrcoef': 0.7574799063925757,\n",
       " 'weighted': {'precision': 0.869867277425417,\n",
       "  'recall': 0.8653198653198653,\n",
       "  'f1': 0.8445908280663593},\n",
       " 'macro': {'precision': 0.8768895348837209,\n",
       "  'recall': 0.7115109229183006,\n",
       "  'f1': 0.7563655755963362},\n",
       " 'micro': {'precision': 0.8653198653198653,\n",
       "  'recall': 0.8653198653198653,\n",
       "  'f1': 0.8653198653198653}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_validation_pipeline('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: lasbe has a dimensionality of: 768\n",
      "Loading model....\n",
      "Running pridictions....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9629629629629629,\n",
       " 'simples_accuracy': 0.9629629629629629,\n",
       " 'matthews_corrcoef': 0.9349615320604401,\n",
       " 'weighted': {'precision': 0.9658796426598283,\n",
       "  'recall': 0.9629629629629629,\n",
       "  'f1': 0.9610253068317585},\n",
       " 'macro': {'precision': 0.9453560371517028,\n",
       "  'recall': 0.936046511627907,\n",
       "  'f1': 0.9337634408602151},\n",
       " 'micro': {'precision': 0.9629629629629629,\n",
       "  'recall': 0.9629629629629629,\n",
       "  'f1': 0.9629629629629629}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_validation_pipeline('lasbe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data....\n",
      "The embedding: use has a dimensionality of: 512\n",
      "Loading model....\n",
      "Running pridictions....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9629629629629629,\n",
       " 'simples_accuracy': 0.9629629629629629,\n",
       " 'matthews_corrcoef': 0.9347756681090932,\n",
       " 'weighted': {'precision': 0.9649410774410774,\n",
       "  'recall': 0.9629629629629629,\n",
       "  'f1': 0.9612413759459713},\n",
       " 'macro': {'precision': 0.9703125,\n",
       "  'recall': 0.9375501202886929,\n",
       "  'f1': 0.9496261684806344},\n",
       " 'micro': {'precision': 0.9629629629629629,\n",
       "  'recall': 0.9629629629629629,\n",
       "  'f1': 0.9629629629629629}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_validation_pipeline('use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[Pará State]Text_Classification.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "da386d383b1a4f2ab977ab0cc371ee70ac9bd2160da3f0bf5cca7f94d497a6a3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "da386d383b1a4f2ab977ab0cc371ee70ac9bd2160da3f0bf5cca7f94d497a6a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
