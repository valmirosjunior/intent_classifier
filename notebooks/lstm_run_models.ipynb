{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zL6SjRcWyrkQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 17:33:34.385984: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-19 17:33:34.386000: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.annotator import Tokenizer as SparkTokenizer\n",
    "from sparknlp.base import DocumentAssembler\n",
    "\n",
    "from src.core import file_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/19 17:33:36 WARN Utils: Your hostname, notavel resolves to a loopback address: 127.0.1.1; using 192.168.0.7 instead (on interface wlo1)\n",
      "22/06/19 17:33:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Ivy Default Cache set to: /home/valmir/.ivy2/cache\n",
      "The jars for the packages stored in: /home/valmir/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp-spark32_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7dd38078-7248-4425-abdc-9c7383df8ed8;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/valmir/dev/python/intent_classifier/venv/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound com.johnsnowlabs.nlp#spark-nlp-spark32_2.12;3.4.2 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.5.3 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.603 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
      "\tfound net.jcip#jcip-annotations;1.0 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.21 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound org.json4s#json4s-ext_2.12;3.7.0-M11 in central\n",
      "\tfound joda-time#joda-time;2.10.10 in central\n",
      "\tfound org.joda#joda-convert;2.2.1 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.3.3 in central\n",
      "\tfound net.sf.trove4j#trove4j;3.0.3 in central\n",
      ":: resolution report :: resolve 339ms :: artifacts dl 15ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.603 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp-spark32_2.12;3.4.2 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.3.3 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjoda-time#joda-time;2.10.10 from central in [default]\n",
      "\tnet.jcip#jcip-annotations;1.0 from central in [default]\n",
      "\tnet.sf.trove4j#trove4j;3.0.3 from central in [default]\n",
      "\torg.joda#joda-convert;2.2.1 from central in [default]\n",
      "\torg.json4s#json4s-ext_2.12;3.7.0-M11 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.5.3 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   21  |   0   |   0   |   0   ||   21  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7dd38078-7248-4425-abdc-9c7383df8ed8\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 21 already retrieved (0kB/7ms)\n",
      "22/06/19 17:33:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = sparknlp.start(spark32=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "  def __init__(self, embedding_name):\n",
    "    self.embedding_name = embedding_name\n",
    "    self.working_dir = fm.filename_from_data_dir(f'output/lstm_models/patient/{self.embedding_name}')\n",
    "    self.model = self.load_lstm_model()\n",
    "    self.vocabullary = self.load_vocabullary()\n",
    "    self.metadata = self.load_metadata()\n",
    "    self.intents = self.metadata['intents']\n",
    "    self.vector_length = int(self.metadata['vector_length'])\n",
    "  \n",
    "\n",
    "  def load_lstm_model(self):\n",
    "    return keras.models.load_model(f'{self.working_dir}/model.h5')\n",
    "\n",
    "  def load_vocabullary(self):\n",
    "    file = open(f'{self.working_dir}/vocabullary.json',\"r\")\n",
    "\n",
    "    return json.load(file)\n",
    "  \n",
    "  def load_metadata(self):\n",
    "    file = open(f'{self.working_dir}/metadata.json',\"r\")\n",
    "\n",
    "    return json.load(file)\n",
    "  \n",
    "\n",
    "  def get_tokens(self, text):\n",
    "    spark_df = spark.createDataFrame([[text]]).toDF(\"text\")\n",
    "\n",
    "    doc_df = DocumentAssembler().setInputCol(\"text\").setOutputCol(\"document\").transform(spark_df)\n",
    "\n",
    "    token_df = SparkTokenizer().setInputCols([\"document\"]).setOutputCol(\"token\").fit(doc_df).transform(doc_df)\n",
    "\n",
    "    return token_df.select('token.result').toPandas().loc[0]['result']\n",
    "\n",
    "  def convert_text_to_input_model(self, tokens):\n",
    "    return [self.vocabullary[token] if token in self.vocabullary else 0 for token in tokens]\n",
    "\n",
    "  def print_intent_probabilities(self, prediction):\n",
    "    print('This is the distribuition of the prediction by intent:')\n",
    "    intent_probabilities = {intent: prediction[0][index] for index, intent in enumerate(self.intents)}\n",
    "\n",
    "    for item in sorted(intent_probabilities.items(), key=lambda item: -item[1]):\n",
    "      print(f'{item[0]} = {(item[1] *100):.4f}%')\n",
    "\n",
    "  def print_pred_real_label(self, text, print_probabilities=False):\n",
    "    tokens = self.get_tokens(text)\n",
    "\n",
    "    indexes_vector = self.convert_text_to_input_model(tokens)\n",
    "\n",
    "    padding_vector = pad_sequences(\n",
    "      maxlen=self.vector_length, sequences=[indexes_vector], value=0, padding='post', truncating='post'\n",
    "    )\n",
    "\n",
    "    prediction = self.model.predict(padding_vector)\n",
    "\n",
    "    index_label_predicted = np.argmax(prediction)\n",
    "    \n",
    "    predicted_label = self.intents[index_label_predicted]    \n",
    "    percentage = f'{(prediction[0][index_label_predicted] *100):.4f}'\n",
    "\n",
    "    print(f'The intent predicted was: {predicted_label} with: {percentage}%\\n')\n",
    "\n",
    "    if print_probabilities:\n",
    "      self.print_intent_probabilities(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bert predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_glove = Predictor('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intent predicted was: inform_symptoms with: 99.9562%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictor_glove.print_pred_real_label('Eu estou com febre e dor de cabeça')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intent predicted was: greeting with: 99.9407%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictor_glove.print_pred_real_label('Olá bom dia, muito obrigado!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intent predicted was: request_inform with: 81.4230%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictor_glove.print_pred_real_label('Gostaria de saber qual remédio, eu devo tomar para fortes dores no peito?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intent predicted was: inform_medicine with: 99.4024%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictor_glove.print_pred_real_label('Estou tomando Tylenol e paracetamol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bert predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_bert_pt = Predictor('bert_pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intent predicted was: inform_symptoms with: 99.9995%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictor_bert_pt.print_pred_real_label('Eu estou com febre e dor de cabeça')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intent predicted was: greeting with: 99.9946%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictor_bert_pt.print_pred_real_label('Olá bom dia, muito obrigado!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intent predicted was: request_inform with: 99.9879%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictor_bert_pt.print_pred_real_label('Gostaria de saber qual remédio, eu devo tomar para fortes dores no peito?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intent predicted was: inform_symptoms with: 75.7815%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictor_bert_pt.print_pred_real_label('Estou tomando Tylenol e paracetamol')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[Pará State]Text_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
